{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca196370",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils.data_load import load_all_participants\n",
    "from utils.cm_plot import plot_regression_results,plot_confusion_matrix\n",
    "\n",
    "from models.cnn import MultiHeadConv1DModel\n",
    "from models.mlp import MLPModel\n",
    "from models.transformer import FeatureGroupTransformerModel\n",
    "from models.additional import *\n",
    "\n",
    "all_participants_data = load_all_participants()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04aadc",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af432d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(all_participants_data, task_type='binary', model_type='transformer',\n",
    "              batch_size=32, learning_rate=0.001, num_epochs=20):\n",
    "\n",
    "    # 1) Device setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Model type: {model_type}, Task type: {task_type}\")\n",
    "\n",
    "    # 2) Data preparation\n",
    "    if model_type == 'cnn':\n",
    "        X, y_binary, y_ternary, y_continuous, groups, feature_columns = prepare_data_for_pytorch(all_participants_data)\n",
    "        feature_groups = create_token_groups(all_participants_data)\n",
    "        model_name_for_plotting = \"cnn\"\n",
    "    elif model_type == 'transformer':\n",
    "        X, y_binary, y_ternary, y_continuous, groups, feature_columns = prepare_data_for_pytorch(all_participants_data)\n",
    "        feature_groups = create_token_groups(all_participants_data)\n",
    "        model_name_for_plotting = \"transformer\"\n",
    "        print(\"Feature groups created (total {}):\".format(len(feature_groups)))\n",
    "        for name in feature_groups:\n",
    "            print(f\"  {name}\")\n",
    "    else: #MLP\n",
    "        X, y_binary, y_ternary, y_continuous, groups, feature_columns = prepare_data_for_pytorch(all_participants_data)\n",
    "        model_name_for_plotting = \"mlp\"\n",
    "        print(f\"Using MLP model with {X.shape[1]} input features\")\n",
    "\n",
    "    # 3) Select target\n",
    "    if task_type == 'binary':\n",
    "        y = y_binary\n",
    "    elif task_type == 'ternary':\n",
    "        y = y_ternary\n",
    "    else:\n",
    "        y = y_continuous\n",
    "        task_type = 'continuous'\n",
    "\n",
    "    # 4) LOSO cross‑validation setup\n",
    "    unique_groups = np.unique(groups)\n",
    "    n_splits = len(unique_groups)\n",
    "    if n_splits < 2:\n",
    "        print(f\"Warning: Only {n_splits} unique groups; skipping CV.\")\n",
    "        return None\n",
    "    cv_loso = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    fold_metrics = []\n",
    "\n",
    "    # 5) Loop over folds\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv_loso.split(X, y, groups), start=1):\n",
    "        test_subject = groups[test_idx[0]]\n",
    "        print(f\"\\nFold {fold}/{n_splits} — testing on subject: {test_subject}\")\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        train_ds = create_torch_dataset(X_train, y_train, task_type)\n",
    "        test_ds  = create_torch_dataset(X_test, y_test, task_type)\n",
    "        pin_mem = torch.cuda.is_available()\n",
    "        train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size,\n",
    "                                                   shuffle=True, pin_memory=pin_mem,\n",
    "                                                   num_workers=2 if pin_mem else 0)\n",
    "        test_loader  = torch.utils.data.DataLoader(test_ds,  batch_size=batch_size,\n",
    "                                                   shuffle=False, pin_memory=pin_mem,\n",
    "                                                   num_workers=2 if pin_mem else 0)\n",
    "\n",
    "        if task_type == 'binary':\n",
    "            output_size = 1\n",
    "            criterion = nn.BCELoss()\n",
    "        elif task_type == 'ternary':\n",
    "            output_size = 3\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            output_size = 1\n",
    "            criterion = nn.MSELoss()\n",
    "\n",
    "        if model_type == 'transformer':\n",
    "            model = FeatureGroupTransformerModel(feature_groups, output_size, task_type)\n",
    "        elif model_type == 'cnn':\n",
    "            model = MultiHeadConv1DModel(feature_groups, output_size, task_type)\n",
    "           \n",
    "        else:\n",
    "            model = MLPModel(X_train.shape[1], output_size, task_type)\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min' if task_type == 'continuous' else 'max',\n",
    "            factor=0.5,\n",
    "            patience=3\n",
    "        )\n",
    "\n",
    "        # 6) Training loop\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs = inputs.to(device, non_blocking=pin_mem)\n",
    "                targets = targets.to(device, non_blocking=pin_mem)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "            val_loss, val_metric = evaluate_model(model, test_loader, criterion, device, task_type)\n",
    "            metric_name = \"Accuracy\" if task_type in ['binary','ternary'] else \"RMSE\"\n",
    "            print(f\"  Epoch {epoch}/{num_epochs}, Loss: {avg_loss:.4f}, Val {metric_name}: {val_metric:.4f}\")\n",
    "\n",
    "            if task_type == 'continuous':\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step(val_metric)\n",
    "\n",
    "        # 7) Final evaluation\n",
    "        model.eval()\n",
    "        preds, tgts = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs = inputs.to(device, non_blocking=pin_mem)\n",
    "                outputs = model(inputs)\n",
    "                if task_type == 'binary':\n",
    "                    batch_preds = (outputs > 0.5).float().cpu().numpy()\n",
    "                elif task_type == 'ternary':\n",
    "                    batch_preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                else:\n",
    "                    batch_preds = outputs.cpu().numpy()\n",
    "                preds.extend(batch_preds.flatten())\n",
    "                tgts.extend(targets.cpu().numpy().flatten())\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        tgts  = np.array(tgts)\n",
    "        all_predictions.extend(preds)\n",
    "        all_targets.extend(tgts)\n",
    "\n",
    "        if task_type in ['binary', 'ternary']:\n",
    "            score = accuracy_score(tgts, preds)\n",
    "            print(f\"  Subject {test_subject} — Accuracy: {score:.4f}\")\n",
    "        else:\n",
    "            score = np.sqrt(mean_squared_error(tgts, preds))\n",
    "            print(f\"  Subject {test_subject} — RMSE: {score:.4f}\")\n",
    "        fold_metrics.append((test_subject, score))\n",
    "\n",
    "        del model, optimizer, scheduler, train_loader, test_loader\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    all_preds = np.array(all_predictions)\n",
    "    all_tgts  = np.array(all_targets)\n",
    "\n",
    "    if task_type in ['binary', 'ternary']:\n",
    "        overall = accuracy_score(all_tgts, all_preds)\n",
    "        print(f\"\\nOverall Accuracy: {overall:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        cm = confusion_matrix(all_tgts, all_preds)\n",
    "        print(cm)\n",
    "        plot_confusion_matrix(all_tgts, all_preds, task_type, model_name_for_plotting)\n",
    "    else:\n",
    "        overall = np.sqrt(mean_squared_error(all_tgts, all_preds))\n",
    "        print(f\"\\nOverall RMSE: {overall:.4f}\")\n",
    "        plot_regression_results(all_tgts, all_preds,model_name_for_plotting)\n",
    "\n",
    "    results = {\n",
    "        'model_type': model_name_for_plotting,\n",
    "        'task_type': task_type,\n",
    "        'fold_metrics': fold_metrics,\n",
    "        'predictions': all_preds,\n",
    "        'targets': all_tgts,\n",
    "        'overall_accuracy' if task_type in ['binary','ternary'] else 'overall_rmse': overall\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ea9eb",
   "metadata": {},
   "source": [
    "# USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "group_results = run_model(\n",
    "    all_participants_data, \n",
    "    task_type='binary',\n",
    "    model_type='cnn',\n",
    "    batch_size=128,\n",
    "    learning_rate=0.00005,\n",
    "    num_epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "group_results = run_model(\n",
    "    all_participants_data, \n",
    "    task_type='ternary',\n",
    "    model_type='transformer',\n",
    "    batch_size=128,\n",
    "    learning_rate=0.00005,\n",
    "    num_epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182cc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "group_results = run_model(\n",
    "    all_participants_data, \n",
    "    task_type='continous',\n",
    "    model_type='mlp',\n",
    "    batch_size=128,\n",
    "    learning_rate=0.00005,\n",
    "    num_epochs=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
