{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca196370",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_load import load_all_participants\n",
    "from utils.cm_plot import plot_binary_confusion_matrix,plot_ternary_confusion_matrix,plot_continous_perclos\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.model_selection import GroupKFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error\n",
    "\n",
    "all_participants_data = load_all_participants()\n",
    "\n",
    "X = all_participants_data.drop(\n",
    "    columns=[\"perclos\", \"quantized_perclos\", \"Participant Name\"]\n",
    ")\n",
    "groups = all_participants_data[\"Participant Name\"]\n",
    "cv_loso = GroupKFold(n_splits=len(groups.unique()))\n",
    "\n",
    "y_binary_encoded = (all_participants_data[\"perclos\"] > 0.5).astype(int)\n",
    "y_ternary_encoded = all_participants_data[\"quantized_perclos\"]\n",
    "y_continuous = all_participants_data[\"perclos\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2a4ce",
   "metadata": {},
   "source": [
    "# LOADER + MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class SEEDViGDataset(Dataset):\n",
    "    def __init__(self, X, y, is_regression=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.is_regression = is_regression\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_item = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        if self.is_regression:\n",
    "            # For regression, keep labels as float\n",
    "            y_item = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        else:\n",
    "            # For classification, cast labels to long (integer)\n",
    "            y_item = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return x_item, y_item\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.classifier = nn.Linear(32, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.features(x)\n",
    "        x = x.squeeze(-1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, nhead=8, num_layers=3):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, 64)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc_out = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a8034",
   "metadata": {},
   "source": [
    "# TRAINING LOOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2defb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, task_type):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    truths = []\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            if task_type == \"regression\":\n",
    "                preds.append(outputs.cpu().numpy().flatten())\n",
    "                truths.append(y_batch.cpu().numpy().flatten())\n",
    "            else:\n",
    "                # For classification, take argmax of logits\n",
    "                preds.append(outputs.argmax(dim=1).cpu().numpy())\n",
    "                truths.append(y_batch.cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return total_loss / len(dataloader), preds, truths\n",
    "\n",
    "\n",
    "def run_pytorch_model(X, y, groups, model_type=\"cnn\", task_type=\"binary\", epochs=5):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if task_type == \"binary\":\n",
    "        output_dim = 2\n",
    "        is_regression = False\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    elif task_type == \"ternary\":\n",
    "        output_dim = 3\n",
    "        is_regression = False\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        output_dim = 1\n",
    "        is_regression = True\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=len(np.unique(groups)))\n",
    "    splits = list(group_kfold.split(X, y, groups=groups))\n",
    "\n",
    "    all_preds = []\n",
    "    all_truths = []\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "        print(f\"\\nStarting fold {fold_idx}/{len(splits)}\")\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        train_dataset = SEEDViGDataset(X_train, y_train, is_regression=is_regression)\n",
    "        test_dataset = SEEDViGDataset(X_test, y_test, is_regression=is_regression)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        input_dim = X_train.shape[1]\n",
    "        if model_type == \"cnn\":\n",
    "            model = SimpleCNN(input_dim, output_dim)\n",
    "        else:\n",
    "            model = SimpleTransformer(input_dim, output_dim)\n",
    "\n",
    "        model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        for epoch in tqdm(range(epochs), desc=f\"Fold {fold_idx} training\"):\n",
    "            train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "        test_loss, preds, truths = evaluate(model, test_loader, criterion, device, task_type)\n",
    "        all_preds.append(preds)\n",
    "        all_truths.append(truths)\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_truths = np.concatenate(all_truths)\n",
    "\n",
    "    if task_type == \"regression\":\n",
    "        mse = np.mean((all_preds - all_truths) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(\"Regression RMSE:\", rmse)\n",
    "    else:\n",
    "        acc = accuracy_score(all_truths, all_preds)\n",
    "        print(\"Classification Accuracy:\", acc)\n",
    "        cm = confusion_matrix(all_truths, all_preds)\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ea9eb",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification \n",
    "run_pytorch_model(X.values, y_binary_encoded.values, groups.values, model_type=\"transformer\", task_type=\"binary\", epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ff6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ternary classification \n",
    "run_pytorch_model(X.values, y_ternary_encoded.values, groups.values, model_type=\"transformer\", task_type=\"ternary\", epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Continuous regression \n",
    "run_pytorch_model(X.values, y_continuous.values, groups.values, model_type=\"transformer\", task_type=\"regression\", epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
