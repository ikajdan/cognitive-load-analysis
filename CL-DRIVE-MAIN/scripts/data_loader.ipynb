{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dir = 'C:/Users/janis/Documents/GitHub/PM_EEG_CONTROL/dataverse_files'\n",
    "base_dir = \"C:/Users/janis/Desktop/dataverse_files\"\n",
    "\n",
    "# Loading all participants into a single dictionary\n",
    "all_data = load_all_data(base_dir)\n",
    "print(\"Loaded data for subjects:\", list(all_data.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CLDriveDataset(Dataset):\n",
    "\n",
    "    def __init__(self, base_dir: str):\n",
    "        self.base_dir = base_dir\n",
    "        eeg_dir = os.path.join(base_dir, 'EEG')\n",
    "        self.subject_ids = []\n",
    "        if os.path.isdir(eeg_dir):\n",
    "            for folder in os.listdir(eeg_dir):\n",
    "                folder_path = os.path.join(eeg_dir, folder)\n",
    "                if os.path.isdir(folder_path):\n",
    "                    self.subject_ids.append(folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subject_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_id = self.subject_ids[idx]\n",
    "        subject_data = load_subject_data(self.base_dir, subject_id)\n",
    "        return subject_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "\n",
    "    collated = {}\n",
    "    modalities = ['EEG', 'ECG', 'EDA', 'Gaze']\n",
    "    labels_key = 'Labels'\n",
    "    \n",
    "    # Initialize dictionaries for each modality and level\n",
    "    for mod in modalities:\n",
    "        collated[mod] = {}\n",
    "        for level in range(1, 10):\n",
    "            collated[mod][level] = {'data': [], 'baseline': []}\n",
    "\n",
    "    collated[labels_key] = []\n",
    "\n",
    "    # Iterate over each sample in the batch\n",
    "    for sample in batch:\n",
    "        # Process each modality\n",
    "        for mod in modalities:\n",
    "            mod_data = sample.get(mod, None)\n",
    "            if mod_data is not None:\n",
    "                for level, level_data in mod_data.items():\n",
    "                    df_data = level_data['data']\n",
    "                    df_baseline = level_data['baseline']\n",
    "                    # Ensure 'Timestamp' is present\n",
    "                    if 'Timestamp' not in df_data.columns or 'Timestamp' not in df_baseline.columns:\n",
    "                        continue\n",
    "                    # Merge data and baseline on 'Timestamp'\n",
    "                    merged_data = pd.merge(df_data, df_baseline, on='Timestamp', suffixes=('_data', '_baseline'))\n",
    "                    # Drop rows with any NaNs\n",
    "                    merged_data = merged_data.dropna()\n",
    "                    if merged_data.empty:\n",
    "                        continue\n",
    "                    # Extract features (drop 'Timestamp')\n",
    "                    data_features = merged_data.drop(columns=['Timestamp'])\n",
    "                    baseline_features = merged_data.drop(columns=['Timestamp'])\n",
    "                    # Convert to numpy and then to tensors\n",
    "                    data_tensor = torch.tensor(data_features.to_numpy(dtype=np.float32))\n",
    "                    baseline_tensor = torch.tensor(baseline_features.to_numpy(dtype=np.float32))\n",
    "                    # Append to collated\n",
    "                    collated[mod][level]['data'].append(data_tensor)\n",
    "                    collated[mod][level]['baseline'].append(baseline_tensor)\n",
    "        \n",
    "        # Process Labels\n",
    "        labels_df = sample.get(labels_key, None)\n",
    "        if labels_df is not None and 'time' in labels_df.columns:\n",
    "            # Drop rows with any NaNs\n",
    "            labels_df_clean = labels_df.dropna()\n",
    "            if not labels_df_clean.empty:\n",
    "                # Drop 'time' column\n",
    "                labels_features = labels_df_clean.drop(columns=['time'])\n",
    "                labels_tensor = torch.tensor(labels_features.to_numpy(dtype=np.float32))\n",
    "                collated[labels_key].append(labels_tensor)\n",
    "\n",
    "    # Stack tensors for each modality and level\n",
    "    for mod in modalities:\n",
    "        for level in range(1, 10):\n",
    "            if collated[mod][level]['data']:\n",
    "                # Concatenate along the first dimension (batch dimension)\n",
    "                collated[mod][level]['data'] = torch.cat(collated[mod][level]['data'], dim=0)\n",
    "            else:\n",
    "                collated[mod][level]['data'] = None\n",
    "            if collated[mod][level]['baseline']:\n",
    "                collated[mod][level]['baseline'] = torch.cat(collated[mod][level]['baseline'], dim=0)\n",
    "            else:\n",
    "                collated[mod][level]['baseline'] = None\n",
    "\n",
    "    # Stack Labels\n",
    "    if collated[labels_key]:\n",
    "        collated[labels_key] = torch.stack(collated[labels_key], dim=0)\n",
    "    else:\n",
    "        collated[labels_key] = None\n",
    "\n",
    "    return collated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "  EEG Level 1: Data shape torch.Size([1024, 8]), Baseline shape torch.Size([1024, 8])\n",
      "  EEG Level 2: Data shape torch.Size([1024, 8]), Baseline shape torch.Size([1024, 8])\n",
      "  EEG Level 3: Data shape torch.Size([1024, 8]), Baseline shape torch.Size([1024, 8])\n",
      "  EEG Level 4: Data shape torch.Size([1023, 8]), Baseline shape torch.Size([1023, 8])\n",
      "  EEG Level 5: Data shape torch.Size([768, 8]), Baseline shape torch.Size([768, 8])\n",
      "  EEG Level 6: Data shape torch.Size([767, 8]), Baseline shape torch.Size([767, 8])\n",
      "  EEG Level 7: Data shape torch.Size([1381, 8]), Baseline shape torch.Size([1381, 8])\n",
      "  EEG Level 8: Data shape torch.Size([768, 8]), Baseline shape torch.Size([768, 8])\n",
      "  EEG Level 9: Data shape torch.Size([768, 8]), Baseline shape torch.Size([768, 8])\n",
      "  Labels shape: torch.Size([3, 18, 9])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dataset\n",
    "dataset = CLDriveDataset(base_dir=base_dir )\n",
    "\n",
    "# Initialize the DataLoader with the custom collate function\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,           # Adjust batch size as needed\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate_fn\n",
    ")\n",
    "\n",
    "# Example: Iterating through the DataLoader\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    \n",
    "    # Accessing EEG data\n",
    "    eeg_data = batch['EEG']\n",
    "    if eeg_data:\n",
    "        for level, level_data in eeg_data.items():\n",
    "            if level_data['data'] is not None:\n",
    "                print(f\"  EEG Level {level}: Data shape {level_data['data'].shape}, Baseline shape {level_data['baseline'].shape}\")\n",
    "            else:\n",
    "                print(f\"  EEG Level {level}: No data\")\n",
    "    \n",
    "    # Accessing Labels\n",
    "    labels = batch['Labels']\n",
    "    if labels is not None:\n",
    "        print(f\"  Labels shape: {labels.shape}\")\n",
    "    else:\n",
    "        print(\"  No Labels found\")\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
