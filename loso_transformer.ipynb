{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca196370",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils.data_load import load_all_participants\n",
    "\n",
    "all_participants_data = load_all_participants()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc06aa",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc62c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeatureGroupTransformerModel(nn.Module):\n",
    "    def __init__(self, feature_groups, output_size, task_type='binary'):\n",
    "        super(FeatureGroupTransformerModel, self).__init__()\n",
    "\n",
    "        self.feature_groups = feature_groups\n",
    "        self.group_names = list(feature_groups.keys())\n",
    "        self.num_groups = len(feature_groups)\n",
    "        self.task_type = task_type\n",
    "\n",
    "        self.embedding_dim = 64\n",
    "        self.num_heads = 8\n",
    "        self.num_encoder_layers = 3\n",
    "\n",
    "        self.feature_encoders = nn.ModuleDict()\n",
    "        for group_name in self.group_names:\n",
    "            _, group_size = feature_groups[group_name]\n",
    "            self.feature_encoders[group_name] = nn.Sequential(\n",
    "                nn.Linear(group_size, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, self.embedding_dim)\n",
    "            )\n",
    "\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1, self.num_groups, self.embedding_dim) * 0.1)\n",
    "        self.group_type_embedding = nn.Parameter(torch.randn(1, self.num_groups, self.embedding_dim) * 0.1)\n",
    "\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=self.embedding_dim,\n",
    "            nhead=self.num_heads,\n",
    "            dim_feedforward=128,\n",
    "            dropout=0.5,\n",
    "            activation='relu',\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layers,\n",
    "            num_layers=self.num_encoder_layers,\n",
    "            norm=nn.LayerNorm(self.embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.attention_scorer = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        self.output_layers = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "\n",
    "        if task_type == 'binary':\n",
    "            self.output_activation = nn.Sigmoid()\n",
    "        elif task_type == 'ternary':\n",
    "            self.output_activation = None\n",
    "        else:\n",
    "            self.output_activation = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x, return_attention_weights=False): # Added flag for visualization later\n",
    "        batch_size = x.size(0)\n",
    "        group_embeddings = []\n",
    "\n",
    "        for group_name in self.group_names:\n",
    "            start_idx, group_size = self.feature_groups[group_name]\n",
    "            group_features = x[:, start_idx : start_idx + group_size]\n",
    "            group_embedding = self.feature_encoders[group_name](group_features)\n",
    "            group_embeddings.append(group_embedding)\n",
    "\n",
    "        encoded_groups = torch.stack(group_embeddings, dim=1)\n",
    "        encoded_groups = encoded_groups + self.pos_encoding + self.group_type_embedding\n",
    "        transformer_output = self.transformer_encoder(encoded_groups)\n",
    "\n",
    "        attn_scores = self.attention_scorer(transformer_output)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        pooled_output = torch.sum(transformer_output * attn_weights, dim=1)\n",
    "\n",
    "        final_output = self.output_layers(pooled_output)\n",
    "        if self.output_activation is not None:\n",
    "            final_output = self.output_activation(final_output)\n",
    "\n",
    "        if return_attention_weights:\n",
    "            return final_output, attn_weights.squeeze(-1)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "    @staticmethod\n",
    "    def create_token_groups(all_participants_data):\n",
    "        feature_groups = {}\n",
    "        columns_to_drop = [\"perclos\", \"quantized_perclos\", \"Participant Name\"]\n",
    "        columns_to_process = [col for col in all_participants_data.columns if col not in columns_to_drop]\n",
    "\n",
    "        col_to_X_index = {col: i for i, col in enumerate(columns_to_process)}\n",
    "\n",
    "        eeg_types = [\"EEG_2Hz\", \"EEG_5Bands\"]\n",
    "        forehead_types = [\"Forehead_EEG_2Hz\", \"Forehead_EEG_5Bands\"]\n",
    "\n",
    "\n",
    "        for feature_type in eeg_types:\n",
    "            channel_features = [col for col in columns_to_process if col.startswith(feature_type)]\n",
    "            channels = sorted(list(set(\n",
    "                col.split('_')[2].replace('ch', '')\n",
    "                for col in channel_features if '_ch' in col and len(col.split('_')) > 2 and col.split('_')[2].startswith('ch')\n",
    "            )))\n",
    "            for ch in channels:\n",
    "                group_cols = [col for col in channel_features if f\"_ch{ch}_\" in col]\n",
    "                if not group_cols:\n",
    "                    continue\n",
    "                indices = [col_to_X_index[col] for col in group_cols]\n",
    "                if not indices: continue\n",
    "                feature_groups[f\"{feature_type}_Channel_{ch}\"] = (min(indices), len(indices))\n",
    "\n",
    "        for feature_type in forehead_types:\n",
    "            channel_features = [col for col in columns_to_process if col.startswith(feature_type)]\n",
    "            channels = sorted(list(set(\n",
    "                col.split('_')[3].replace('ch', '')\n",
    "                for col in channel_features if '_ch' in col and len(col.split('_')) > 3 and col.split('_')[3].startswith('ch')\n",
    "            )))\n",
    "            for ch in channels:\n",
    "                group_cols = [col for col in channel_features if f\"_ch{ch}_\" in col]\n",
    "                if not group_cols:\n",
    "                    continue\n",
    "                indices = [col_to_X_index[col] for col in group_cols]\n",
    "                if not indices: continue\n",
    "                feature_groups[f\"{feature_type}_Channel_{ch}\"] = (min(indices), len(indices))\n",
    "\n",
    "        eog_features = [col for col in columns_to_process if col.startswith(\"EOG\")]\n",
    "        if eog_features:\n",
    "            eog_indices = [col_to_X_index[col] for col in eog_features]\n",
    "            if eog_indices:\n",
    "                 feature_groups[\"EOG\"] = (min(eog_indices), len(eog_indices))\n",
    "\n",
    "        return feature_groups\n",
    "\n",
    "\n",
    "def prepare_data_for_pytorch(all_participants_data):\n",
    "    columns_to_drop = [\"perclos\", \"quantized_perclos\", \"Participant Name\"]\n",
    "    feature_columns = [col for col in all_participants_data.columns if col not in columns_to_drop]\n",
    "\n",
    "    X = all_participants_data[feature_columns].values\n",
    "\n",
    "    y_binary = (all_participants_data[\"perclos\"] > 0.5).astype(int).values\n",
    "    y_ternary = all_participants_data[\"quantized_perclos\"].values\n",
    "    y_continuous = all_participants_data[\"perclos\"].values\n",
    "\n",
    "    groups = all_participants_data[\"Participant Name\"].values\n",
    "\n",
    "    return X, y_binary, y_ternary, y_continuous, groups\n",
    "\n",
    "def create_torch_dataset(X, y, task_type):\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    if task_type == 'ternary':\n",
    "        y_tensor = torch.LongTensor(y)\n",
    "    elif task_type == 'binary':\n",
    "        y_tensor = torch.FloatTensor(y).view(-1, 1)\n",
    "    else:\n",
    "        y_tensor = torch.FloatTensor(y).view(-1, 1)\n",
    "    return torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, task_type):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets_device = targets.to(device) # Keep targets on device for loss calc\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets_device)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if task_type == 'binary':\n",
    "                preds = (outputs > 0.5).float().cpu().numpy()\n",
    "            elif task_type == 'ternary':\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            else:\n",
    "                preds = outputs.cpu().numpy()\n",
    "\n",
    "            all_predictions.extend(preds.flatten())\n",
    "            # Targets moved to CPU only when needed for extending list\n",
    "            all_targets.extend(targets.cpu().numpy().flatten())\n",
    "\n",
    "    all_predictions_np = np.array(all_predictions)\n",
    "    all_targets_np = np.array(all_targets)\n",
    "\n",
    "    if task_type == 'binary' or task_type == 'ternary':\n",
    "        # Ensure predictions are appropriate type/shape if necessary before accuracy_score\n",
    "        accuracy = accuracy_score(all_targets_np, all_predictions_np)\n",
    "        return running_loss / len(test_loader), accuracy\n",
    "    else:\n",
    "        rmse = np.sqrt(mean_squared_error(all_targets_np, all_predictions_np))\n",
    "        return running_loss / len(test_loader), rmse\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(all_targets, all_predictions, task_type, model_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(all_targets, all_predictions)\n",
    "    if task_type == 'binary':\n",
    "        labels = [\"Class 0\", \"Class 1\"]\n",
    "        cmap = \"Blues\"\n",
    "        title = f\"{model_name.upper()} Binary Classification Confusion Matrix\"\n",
    "    else: # ternary\n",
    "        # Determine actual unique labels present in targets and predictions\n",
    "        unique_labels = sorted(list(np.unique(np.concatenate((all_targets, all_predictions)))))\n",
    "        # Ensure labels list matches the unique classes found\n",
    "        if len(unique_labels) == 3:\n",
    "            labels = [\"Class 0\", \"Class 1\", \"Class 2\"]\n",
    "        elif len(unique_labels) == 2: # Handle case where only 2 classes appear\n",
    "             labels = [f\"Class {i}\" for i in unique_labels]\n",
    "             # Adjust confusion matrix size if needed, though confusion_matrix handles this\n",
    "        else: # Fallback for unexpected number of classes\n",
    "             labels = [f\"Class {i}\" for i in unique_labels]\n",
    "\n",
    "        cmap = \"Oranges\"\n",
    "        title = f\"{model_name.upper()} Ternary Classification Confusion Matrix\"\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=cmap, xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_regression_results(all_targets, all_predictions, model_name):\n",
    "    overall_rmse = np.sqrt(mean_squared_error(all_targets, all_predictions))\n",
    "    print(f\"\\nOverall Continuous Regression RMSE: {overall_rmse:.4f}\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(all_targets, all_predictions, alpha=0.5)\n",
    "    min_val = min(np.min(all_targets), np.min(all_predictions)) if len(all_targets) > 0 else 0\n",
    "    max_val = max(np.max(all_targets), np.max(all_predictions)) if len(all_targets) > 0 else 1\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    plt.title(f\"{model_name.upper()} Regression: Predicted vs Actual PERCLOS\")\n",
    "    plt.xlabel(\"Actual PERCLOS\")\n",
    "    plt.ylabel(\"Predicted PERCLOS\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return overall_rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04aadc",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af432d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_feature_group_model(all_participants_data, task_type='binary',\n",
    "                            batch_size=32, learning_rate=0.001, num_epochs=20):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create feature groups using the static method from the model class\n",
    "    feature_groups = FeatureGroupTransformerModel.create_token_groups(all_participants_data)\n",
    "    print(\"Feature groups created (total {}):\".format(len(feature_groups)))\n",
    "    for group_name in feature_groups:\n",
    "        print(group_name)\n",
    "\n",
    "    X, y_binary, y_ternary, y_continuous, groups = prepare_data_for_pytorch(all_participants_data)\n",
    "\n",
    "    if task_type == 'binary':\n",
    "        y = y_binary\n",
    "    elif task_type == 'ternary':\n",
    "        y = y_ternary\n",
    "    else:\n",
    "        y = y_continuous\n",
    "        task_type = 'continuous'\n",
    "\n",
    "    unique_groups = np.unique(groups)\n",
    "\n",
    "    n_splits = len(unique_groups)\n",
    "    if n_splits < 2:\n",
    "        print(f\"Warning: Only {n_splits} unique groups found. Cannot perform GroupKFold with n_splits < 2.\")\n",
    "        return None # \n",
    "    cv_loso = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    fold_metrics = []\n",
    "\n",
    "    # Define group_strategy or model name for reporting\n",
    "    group_strategy = \"channel_eeg_eog_attn_pool\" # Example name\n",
    "    model_name_for_plotting = f\"feature_group_transformer_{group_strategy}\"\n",
    "\n",
    "    # Use X (unscaled) for splitting, scale inside the loop\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv_loso.split(X, y, groups)):\n",
    "        test_subject_identifier = groups[test_idx[0]]\n",
    "        print(f\"\\nFold {fold+1}/{n_splits} - Testing on subject: {test_subject_identifier}\")\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Scale data within the fold\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test) # Use transform only on test\n",
    "\n",
    "        train_dataset = create_torch_dataset(X_train, y_train, task_type)\n",
    "        test_dataset = create_torch_dataset(X_test, y_test, task_type)\n",
    "\n",
    "        pin_memory_flag = torch.cuda.is_available()\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True,\n",
    "            pin_memory=pin_memory_flag, num_workers=2 if pin_memory_flag else 0\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=batch_size, shuffle=False,\n",
    "            pin_memory=pin_memory_flag, num_workers=2 if pin_memory_flag else 0\n",
    "        )\n",
    "\n",
    "        if task_type == 'binary':\n",
    "            output_size = 1\n",
    "            criterion = nn.BCELoss()\n",
    "        elif task_type == 'ternary':\n",
    "            output_size = 3 # Ensure this matches the number of classes in y_ternary\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        else: # continuous\n",
    "            output_size = 1\n",
    "            criterion = nn.MSELoss()\n",
    "\n",
    "        model = FeatureGroupTransformerModel(feature_groups, output_size, task_type).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min' if task_type == 'continuous' else 'max',\n",
    "            factor=0.5, patience=3\n",
    "        )\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs = inputs.to(device, non_blocking=pin_memory_flag)\n",
    "                targets = targets.to(device, non_blocking=pin_memory_flag)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "\n",
    "            # Evaluate every epoch\n",
    "            val_loss, metric = evaluate_model(model, test_loader, criterion, device, task_type)\n",
    "            if task_type == 'continuous':\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step(metric)\n",
    "\n",
    "            metric_name = \"Accuracy\" if task_type in ['binary', 'ternary'] else \"RMSE\"\n",
    "            print(f\"  Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val {metric_name}: {metric:.4f}, \"\n",
    "                  f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        model.eval()\n",
    "        fold_preds = []\n",
    "        fold_targets = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs = inputs.to(device, non_blocking=pin_memory_flag)\n",
    "                outputs = model(inputs)\n",
    "                if task_type == 'binary':\n",
    "                    preds = (outputs > 0.5).float().cpu().numpy()\n",
    "                elif task_type == 'ternary':\n",
    "                    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                else: # continuous\n",
    "                    preds = outputs.cpu().numpy()\n",
    "                fold_preds.extend(preds.flatten())\n",
    "                fold_targets.extend(targets.cpu().numpy().flatten())\n",
    "\n",
    "        fold_preds_np = np.array(fold_preds)\n",
    "        fold_targets_np = np.array(fold_targets)\n",
    "\n",
    "        if task_type in ['binary', 'ternary']:\n",
    "            fold_acc = accuracy_score(fold_targets_np, fold_preds_np)\n",
    "            fold_metrics.append((test_subject_identifier, fold_acc))\n",
    "            print(f\"  Subject {test_subject_identifier} - Final Accuracy: {fold_acc:.4f}\")\n",
    "        else:\n",
    "            fold_rmse = np.sqrt(mean_squared_error(fold_targets_np, fold_preds_np))\n",
    "            fold_metrics.append((test_subject_identifier, fold_rmse))\n",
    "            print(f\"  Subject {test_subject_identifier} - Final RMSE: {fold_rmse:.4f}\")\n",
    "\n",
    "        all_predictions.extend(fold_preds_np)\n",
    "        all_targets.extend(fold_targets_np)\n",
    "\n",
    "        del model, optimizer, scheduler, train_dataset, test_dataset, train_loader, test_loader\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    results = {\n",
    "        'model_type': model_name_for_plotting,\n",
    "        'task_type': task_type,\n",
    "        'fold_metrics': fold_metrics,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets\n",
    "    }\n",
    "\n",
    "    if task_type in ['binary', 'ternary']:\n",
    "        overall_acc = accuracy_score(all_targets, all_predictions)\n",
    "        cm = confusion_matrix(all_targets, all_predictions)\n",
    "        print(f\"\\nOverall {task_type.capitalize()} Classification Accuracy: {overall_acc:.4f}\")\n",
    "        print(\"Overall Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        plot_confusion_matrix(all_targets, all_predictions, task_type, model_name_for_plotting)\n",
    "        results['overall_accuracy'] = overall_acc\n",
    "        results['confusion_matrix'] = cm\n",
    "    else:\n",
    "        overall_rmse = plot_regression_results(all_targets, all_predictions, model_name_for_plotting)\n",
    "        results['overall_rmse'] = overall_rmse\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ea9eb",
   "metadata": {},
   "source": [
    "# USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_results = run_feature_group_model(\n",
    "    all_participants_data, \n",
    "    task_type='binary',\n",
    "    batch_size=64,\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_results = run_feature_group_model(\n",
    "    all_participants_data, \n",
    "    task_type='ternary',\n",
    "    batch_size=64,\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182cc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_results = run_feature_group_model(\n",
    "    all_participants_data, \n",
    "    task_type='continous',\n",
    "    batch_size=64,\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
