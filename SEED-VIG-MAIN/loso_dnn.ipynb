{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca196370",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils.data_load import load_all_participants\n",
    "from utils.cm_plot import plot_regression_results,plot_confusion_matrix\n",
    "\n",
    "from models.cnn import MultiHeadConv1DModel\n",
    "from models.mlp import MLPModel\n",
    "from models.resnet import ResNet1DModel\n",
    "from models.tcn import TCNModel\n",
    "from models.transformer import FeatureGroupTransformerModel\n",
    "from models.additional import *\n",
    "\n",
    "all_participants_data = load_all_participants()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04aadc",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af432d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(all_participants_data,\n",
    "              task_type: str = 'binary',\n",
    "              model_type: str = 'transformer',\n",
    "              batch_size: int = 32,\n",
    "              learning_rate: float = 0.001,\n",
    "              num_epochs: int = 20,\n",
    "              subject_calibration: float = 0.0,\n",
    "              feature_selection: float = 0.0):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device} | Model: {model_type} | Task: {task_type} | Subject calibration: {subject_calibration*100}% \")\n",
    "    print(f\"Batch size: {batch_size} | LR: {learning_rate} |Number of epochs: {num_epochs} | Feature selection: {feature_selection*100}%\")\n",
    "    X, y_binary, y_ternary, y_continuous, groups, feature_columns = prepare_data_for_pytorch(all_participants_data)\n",
    "    original_feature_groups = create_token_groups(all_participants_data)\n",
    "    if model_type in ('cnn', 'transformer'):\n",
    "        feature_groups = original_feature_groups\n",
    "    if task_type == 'binary':\n",
    "        y = y_binary\n",
    "    elif task_type == 'ternary':\n",
    "        y = y_ternary\n",
    "    else:\n",
    "        y, task_type = y_continuous, 'continuous'\n",
    "    unique_groups = np.unique(groups)\n",
    "    if len(unique_groups) < 2:\n",
    "        print(f\"Only {len(unique_groups)} groupsâ€”skipping CV.\")\n",
    "        return\n",
    "    cv = GroupKFold(n_splits=len(unique_groups))\n",
    "    all_preds, all_tgts, fold_metrics = [], [], []\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(X, y, groups), start=1):\n",
    "        subject = groups[test_idx[0]]\n",
    "        print(f\"\\nFold {fold}: test subject {subject}\")\n",
    "        if subject_calibration > 0:\n",
    "            n_calib = int(len(test_idx) * subject_calibration)\n",
    "            n_calib = min(n_calib, len(test_idx)-1)\n",
    "            if n_calib > 0:\n",
    "                calib = np.random.choice(test_idx, n_calib, replace=False)\n",
    "                train_idx = np.concatenate([train_idx, calib])\n",
    "                test_idx = np.setdiff1d(test_idx, calib)\n",
    "                print(f\"  + calibrated {n_calib} samples\")\n",
    "        X_tr, X_te = X[train_idx], X[test_idx]\n",
    "        y_tr, y_te = y[train_idx], y[test_idx]\n",
    "        if 0 < feature_selection < 1:\n",
    "            k = max(1, int(X_tr.shape[1] * feature_selection))\n",
    "            if task_type in ('binary', 'ternary'):\n",
    "                selector = SelectKBest(score_func=f_classif, k=k)\n",
    "            else:\n",
    "                selector = SelectKBest(score_func=f_regression, k=k)\n",
    "            selector.fit(X_tr, y_tr)\n",
    "            mask = selector.get_support()\n",
    "            X_tr = selector.transform(X_tr)\n",
    "            X_te = selector.transform(X_te)\n",
    "            selected_idx = np.where(mask)[0]\n",
    "            feature_groups = {}\n",
    "            for name, (start, size) in original_feature_groups.items():\n",
    "                grp_idx = np.arange(start, start + size)\n",
    "                sel_in_grp = np.intersect1d(grp_idx, selected_idx)\n",
    "                if sel_in_grp.size == 0:\n",
    "                    continue\n",
    "                pos_map = {val: pos for pos, val in enumerate(selected_idx)}\n",
    "                new_pos = [pos_map[i] for i in sel_in_grp]\n",
    "                feature_groups[name] = (min(new_pos), len(new_pos))\n",
    "        else:\n",
    "            feature_groups = original_feature_groups\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(X_tr)\n",
    "        X_te = scaler.transform(X_te)\n",
    "        train_ds = create_torch_dataset(X_tr, y_tr, task_type)\n",
    "        test_ds  = create_torch_dataset(X_te, y_te, task_type)\n",
    "        pin = torch.cuda.is_available()\n",
    "        train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=pin, num_workers=3 if pin else 0)\n",
    "        test_loader  = torch.utils.data.DataLoader(test_ds,  batch_size=batch_size, shuffle=False, pin_memory=pin, num_workers=3 if pin else 0)\n",
    "        if task_type == 'binary':\n",
    "            output_size, criterion = 1, nn.BCELoss()\n",
    "        elif task_type == 'ternary':\n",
    "            output_size, criterion = 3, nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            output_size, criterion = 1, nn.MSELoss()\n",
    "        if model_type == 'transformer':\n",
    "            model = FeatureGroupTransformerModel(feature_groups, output_size, task_type)\n",
    "        elif model_type == 'cnn':\n",
    "            model = MultiHeadConv1DModel(feature_groups, output_size, task_type)\n",
    "        elif model_type == 'resnet':\n",
    "            model = ResNet1DModel(X_tr.shape[1], output_size, task_type)\n",
    "        elif model_type == 'TCN':\n",
    "            model = TCNModel(X_tr.shape[1], output_size, task_type)\n",
    "        else:\n",
    "            model = MLPModel(X_tr.shape[1], output_size, task_type)\n",
    "        model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min' if task_type=='continuous' else 'max', factor=0.5, patience=3)\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            avg = total_loss / len(train_loader)\n",
    "            val_loss, val_metric = evaluate_model(model, test_loader, criterion, device, task_type)\n",
    "            name = \"Accuracy\" if task_type!='continuous' else \"RMSE\"\n",
    "            print(f\" Epoch {epoch}: train_loss={avg:.4f}, val_{name}={val_metric:.4f}\")\n",
    "            scheduler.step(val_loss if task_type=='continuous' else val_metric)\n",
    "        model.eval()\n",
    "        preds, tgts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in test_loader:\n",
    "                xb = xb.to(device)\n",
    "                out = model(xb)\n",
    "                if task_type=='binary':\n",
    "                    p = (out>0.5).float().cpu().numpy()\n",
    "                elif task_type=='ternary':\n",
    "                    p = torch.argmax(out,1).cpu().numpy()\n",
    "                else:\n",
    "                    p = out.cpu().numpy()\n",
    "                preds.extend(p.flatten())\n",
    "                tgts.extend(yb.numpy().flatten())\n",
    "        preds, tgts = np.array(preds), np.array(tgts)\n",
    "        all_preds.extend(preds)\n",
    "        all_tgts.extend(tgts)\n",
    "        if task_type!='continuous':\n",
    "            score = accuracy_score(tgts, preds)\n",
    "            print(f\" Subject {subject} acc={score:.4f}\")\n",
    "        else:\n",
    "            score = np.sqrt(mean_squared_error(tgts, preds))\n",
    "            print(f\" Subject {subject} rmse={score:.4f}\")\n",
    "        fold_metrics.append((subject, score))\n",
    "        del model, optimizer, scheduler, train_loader, test_loader\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    all_preds, all_tgts = np.array(all_preds), np.array(all_tgts)\n",
    "    if task_type!='continuous':\n",
    "        overall = accuracy_score(all_tgts, all_preds)\n",
    "        print(f\"\\nOverall Accuracy: {overall:.4f}\")\n",
    "        print(confusion_matrix(all_tgts, all_preds))\n",
    "        plot_confusion_matrix(all_tgts, all_preds, task_type, model_type)\n",
    "        results_key = 'overall_accuracy'\n",
    "    else:\n",
    "        overall = np.sqrt(mean_squared_error(all_tgts, all_preds))\n",
    "        print(f\"\\nOverall RMSE: {overall:.4f}\")\n",
    "        plot_regression_results(all_tgts, all_preds, model_type)\n",
    "        results_key = 'overall_rmse'\n",
    "    return {\n",
    "        'model_type': model_type,\n",
    "        'task_type': task_type,\n",
    "        'fold_metrics': fold_metrics,\n",
    "        'predictions': all_preds,\n",
    "        'targets': all_tgts,\n",
    "        results_key: overall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ea9eb",
   "metadata": {},
   "source": [
    "# USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "group_results = run_model(\n",
    "    all_participants_data, \n",
    "    task_type='binary',\n",
    "    model_type='TCN',\n",
    "    batch_size=64,\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=3,\n",
    "    subject_calibration= 0.15,\n",
    "    feature_selection = 0.00\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "group_results = run_model(\n",
    "    all_participants_data, \n",
    "    task_type='ternary',\n",
    "    model_type='transformer',\n",
    "    batch_size=64,\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=3,\n",
    "    subject_calibration= 0.15,\n",
    "    feature_selection = 0.00\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182cc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "group_results = run_model(\n",
    "    all_participants_data, \n",
    "    task_type='continuous',\n",
    "    model_type='cnn',\n",
    "    batch_size=64,\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=3,\n",
    "    subject_calibration= 0.15,\n",
    "    feature_selection = 0.00\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
